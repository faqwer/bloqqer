import os
import re

def get_pure_url(line):
    """
    ì–´ë–¤ í˜•íƒœì˜ ì¤„(ì£¼ì„, ê³µë°± í¬í•¨)ì—ì„œë„ ìˆœìˆ˜ URL ë³¸ì²´ë§Œ ì¶”ì¶œí•˜ì—¬ í‘œì¤€í™”í•©ë‹ˆë‹¤.
    """
    # 1. HTML ì£¼ì„ ê¸°í˜¸ ì œê±°
    clean = line.replace('', '').strip()
    
    # 2. ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ httpë¡œ ì‹œì‘í•˜ëŠ” URL ë³¸ì²´ë§Œ ì¶”ì¶œ
    # (ê³µë°±, ì£¼ì„ê¸°í˜¸, ë”°ì˜´í‘œ ë“±ì„ ì œì™¸í•œ ì‹¤ì œ ì£¼ì†Œë§Œ íƒ€ê²ŸíŒ…)
    match = re.search(r'(https?://[^\s<>"]+)', clean)
    if match:
        # ì†Œë¬¸ì ë³€í™˜ ë° ë ìŠ¬ë˜ì‹œ ì œê±°í•˜ì—¬ ë¹„êµ ë°ì´í„° í†µì¼
        return match.group(1).strip().lower().rstrip('/')
    return None

def sync_files(source_file, target_files):
    if not os.path.exists(source_file):
        print(f"âŒ ì›ë³¸ íŒŒì¼({source_file})ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # [ê¸°ì¤€] textURL.mdì—ì„œ URL ëª©ë¡ ì½ê¸°
    with open(source_file, 'r', encoding='utf-8') as f:
        master_urls = [l.strip() for l in f if l.strip()]

    for target_path in target_files:
        if not os.path.exists(target_path):
            print(f"â© {target_path} íŒŒì¼ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        print(f"\n" + "="*50)
        print(f"ğŸ” ëŒ€ìƒ íŒŒì¼: {target_path}")
        
        # ëŒ€ìƒ íŒŒì¼ì˜ ê¸°ì¡´ ë‚´ìš© ë¶„ì„
        existing_lines = []
        existing_url_map = {} # {í‘œì¤€í™”URL: ì›ë³¸ì¤„}
        
        with open(target_path, 'r', encoding='utf-8') as f:
            for line in f:
                raw_line = line.strip()
                if not raw_line: continue
                
                pure = get_pure_url(raw_line)
                if pure:
                    # íŒŒì¼ ì•ˆì— ì´ë¯¸ ìˆëŠ” URLì´ë©´ ë§µì— ê¸°ë¡ (ì²« ë°œê²¬ëœ í˜•íƒœ ìœ ì§€)
                    if pure not in existing_url_map:
                        existing_url_map[pure] = raw_line
        
        # ìƒˆë¡œìš´ ë‚´ìš© êµ¬ì„± (ê¸°ì¤€ íŒŒì¼ ìˆœì„œëŒ€ë¡œ)
        final_output = []
        added_count = 0
        
        for m_url in master_urls:
            m_pure = get_pure_url(m_url)
            
            if m_pure in existing_url_map:
                # [ì´ë¯¸ ìˆìŒ] ì£¼ì„ì´ë“  ì•„ë‹ˆë“  ê¸°ì¡´ì— ìˆë˜ í˜•íƒœ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                final_output.append(existing_url_map[m_pure])
                # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ë§µì—ì„œ ì œê±° (ë‚˜ì¤‘ì— ì¤‘ë³µ ë°ì´í„°ê°€ ë’¤ì— ë¶™ì§€ ì•Šê²Œ)
                del existing_url_map[m_pure]
            else:
                # [ì—†ìŒ] ìƒˆë¡œ ì¶”ê°€
                final_output.append(m_url)
                print(f"  [+] ì‹ ê·œ ì¶”ê°€: {m_url}")
                added_count += 1

        # ì›ë³¸(master)ì—ëŠ” ì—†ì§€ë§Œ ëŒ€ìƒ íŒŒì¼ì—ë§Œ ë‚¨ì•„ìˆë˜ ë‚˜ë¨¸ì§€ ì¤„ë“¤ ì¶”ê°€
        for remaining_line in existing_url_map.values():
            final_output.append(remaining_line)

        # íŒŒì¼ ì €ì¥
        with open(target_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(final_output) + '\n')
        
        print(f"âœ… ë™ê¸°í™” ì™„ë£Œ! (ìƒˆë¡œ ì¶”ê°€ëœ URL: {added_count}ê°œ)")

# --- ì„¤ì •ë¶€ ---
source = 'textURL.md'
targets = ['google.md', 'bing.md', 'naver.md']

if __name__ == "__main__":
    try:
        sync_files(source, targets)
        print("\n" + "â˜…" * 25)
        print(" ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("â˜…" * 25)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print("\nìƒì„¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì‹  í›„ ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    input("Press Enter to exit...")